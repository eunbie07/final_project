# íŒŒì¼ëª…: app_step3.py
# 3ë‹¨ê³„: ì ˆëŒ€ í¬ê¸° ì¶”ì • ì‹œìŠ¤í…œ (ì‹¤ì œ ë°© í¬ê¸°ë¥¼ ëª¨ë¥¼ ë•Œ)

from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import cv2
import numpy as np
import base64
import math
from datetime import datetime
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

class AbsoluteRoomAnalyzer:
    def __init__(self):
        # í•œêµ­ ê±´ì¶• í‘œì¤€ ì¹˜ìˆ˜ (cm)
        self.standard_dimensions = {
            'door': {
                'width': [70, 80, 90],      # ì¼ë°˜ë¬¸ ë„ˆë¹„
                'height': [200, 210, 220],  # ì¼ë°˜ë¬¸ ë†’ì´
                'typical': {'width': 80, 'height': 200}
            },
            'window': {
                'width': [90, 120, 150, 180],   # ì°½ë¬¸ ë„ˆë¹„
                'height': [120, 150, 180],      # ì°½ë¬¸ ë†’ì´  
                'typical': {'width': 120, 'height': 150}
            },
            'outlet': {
                'width': [8, 10, 12],       # ì½˜ì„¼íŠ¸ ë„ˆë¹„
                'height': [8, 10, 12],      # ì½˜ì„¼íŠ¸ ë†’ì´
                'typical': {'width': 10, 'height': 10}
            },
            'ceiling_height': [240, 260, 280],  # ì²œì¥ ë†’ì´
            'room_sizes': {
                # ì¼ë°˜ì ì¸ ë°© í¬ê¸° (ê°€ë¡œ x ì„¸ë¡œ cm)
                'small': [(250, 300), (300, 350)],       # ì‘ì€ ë°©
                'medium': [(300, 400), (350, 450)],      # ì¤‘ê°„ ë°©  
                'large': [(400, 500), (450, 600)]        # í° ë°©
            }
        }
    
    def analyze_image(self, image_data, reference_size=None, options=None):
        """ì ˆëŒ€ í¬ê¸° ì¶”ì • ë¶„ì„"""
        if options is None:
            options = {'detect_windows': True, 'detect_doors': True}
            
        try:
            # ì´ë¯¸ì§€ ë””ì½”ë”©
            image_bytes = base64.b64decode(image_data.split(',')[1])
            image = cv2.imdecode(np.frombuffer(image_bytes, np.uint8), cv2.IMREAD_COLOR)
            
            if image is None:
                raise ValueError("ì´ë¯¸ì§€ë¥¼ ë””ì½”ë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            logger.info(f"ì ˆëŒ€ í¬ê¸° ì¶”ì • ì‹œì‘ - ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")
            
            # 1ë‹¨ê³„: ê³ ê¸‰ ì „ì²˜ë¦¬
            processed_image = self.enhanced_preprocessing(image)
            
            # 2ë‹¨ê³„: í‘œì¤€ ê°ì²´ ê°ì§€ ë° ë¶„ë¥˜
            detected_objects = self.detect_standard_objects(image)
            logger.info(f"ê°ì§€ëœ í‘œì¤€ ê°ì²´: {len(detected_objects)}ê°œ")
            
            # 3ë‹¨ê³„: ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì¶”ì •
            scale_candidates = self.estimate_multiple_scales(detected_objects, image.shape)
            best_scale = self.select_best_scale(scale_candidates)
            logger.info(f"ìµœì  ìŠ¤ì¼€ì¼: {best_scale:.4f} cm/pixel")
            
            # 4ë‹¨ê³„: ë°© ê²½ê³„ì„  ê°ì§€  
            room_corners = self.detect_room_boundaries_advanced(processed_image, detected_objects)
            
            # 5ë‹¨ê³„: í¬ê¸° ê²€ì¦ ë° ë³´ì •
            dimensions = self.calculate_verified_dimensions(room_corners, best_scale, scale_candidates)
            
            # 6ë‹¨ê³„: ì‹ ë¢°ë„ ë° ëŒ€ì•ˆ ì œì‹œ
            analysis_result = self.comprehensive_analysis(dimensions, detected_objects, scale_candidates)
            
            # 7ë‹¨ê³„: ì‹œê°í™”
            result_image = self.absolute_visualization(
                image, room_corners, detected_objects, analysis_result
            )
            
            return {
                'success': True,
                'dimensions': analysis_result['primary'],
                'alternatives': analysis_result['alternatives'],
                'detected_objects': detected_objects,
                'scale_info': {
                    'best_scale': best_scale,
                    'scale_candidates': scale_candidates,
                    'confidence': analysis_result['confidence']
                },
                'result_image': result_image,
                'analysis_info': {
                    'method': 'absolute_estimation_v3',
                    'objects_used': len([obj for obj in detected_objects if obj.get('used_for_scale')]),
                    'timestamp': datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': str(e)}
    
    def enhanced_preprocessing(self, image):
        """í–¥ìƒëœ ì „ì²˜ë¦¬"""
        # ë…¸ì´ì¦ˆ ì œê±°
        denoised = cv2.bilateralFilter(image, 9, 75, 75)
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
        gray = cv2.cvtColor(denoised, cv2.COLOR_BGR2GRAY)
        
        # ì ì‘ì  íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        enhanced = clahe.apply(gray)
        
        return enhanced
    
    def detect_standard_objects(self, image):
        """í‘œì¤€ ì¹˜ìˆ˜ ê°ì²´ ê°ì§€ ë° ë¶„ë¥˜"""
        detected = []
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ë¬¸ ê°ì§€ (ë” ì •êµí•¨)
        doors = self.detect_doors_with_standards(gray, image)
        detected.extend(doors)
        
        # ì°½ë¬¸ ê°ì§€
        windows = self.detect_windows_with_standards(gray, image)
        detected.extend(windows)
        
        # ì½˜ì„¼íŠ¸ ê°ì§€
        outlets = self.detect_outlets_with_standards(gray)
        detected.extend(outlets)
        
        # ì¶”ê°€: íƒ€ì¼/íŒ¨í„´ ê°ì§€
        patterns = self.detect_floor_patterns(gray)
        detected.extend(patterns)
        
        return detected
    
    def detect_doors_with_standards(self, gray, color_image):
        """í‘œì¤€ ì¹˜ìˆ˜ ê¸°ë°˜ ë¬¸ ê°ì§€"""
        doors = []
        
        # ì—£ì§€ ê°•í™”
        edges = cv2.Canny(gray, 50, 150)
        
        # ìˆ˜ì§ ë¼ì¸ ê°•ì¡° (ë¬¸ì€ ì„¸ë¡œê°€ ê¸´ í˜•íƒœ)
        kernel_v = np.array([[-1, 2, -1], [-1, 2, -1], [-1, 2, -1]], dtype=np.float32)
        vertical_edges = cv2.filter2D(edges, -1, kernel_v)
        
        contours, _ = cv2.findContours(vertical_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for contour in contours:
            area = cv2.contourArea(contour)
            if 2000 < area < 100000:
                x, y, w, h = cv2.boundingRect(contour)
                aspect_ratio = h / w
                
                # ë¬¸ì˜ ì¢…íš¡ë¹„ ì²´í¬ (ë†’ì´/ë„ˆë¹„ = 2.0~3.5)
                if 2.0 < aspect_ratio < 3.5:
                    # ì¶”ê°€ ê²€ì¦
                    confidence = self.verify_door_features(color_image[y:y+h, x:x+w], gray[y:y+h, x:x+w])
                    
                    if confidence > 0.3:
                        # í‘œì¤€ ì¹˜ìˆ˜ì™€ ë§¤ì¹­
                        estimated_size = self.match_door_standards(w, h)
                        
                        doors.append({
                            'type': 'door',
                            'bbox': (x, y, w, h),
                            'confidence': confidence,
                            'aspect_ratio': aspect_ratio,
                            'estimated_real_size': estimated_size,
                            'pixel_size': {'width': w, 'height': h}
                        })
        
        return doors
    
    def verify_door_features(self, color_roi, gray_roi):
        """ë¬¸ íŠ¹ì§• ê²€ì¦"""
        if color_roi.size == 0:
            return 0.0
        
        confidence = 0.0
        
        # 1. ìƒ‰ìƒ ë¶„ì„ (ë¬¸ì€ ë³´í†µ ê°ˆìƒ‰, í°ìƒ‰, íšŒìƒ‰ ê³„ì—´)
        hsv = cv2.cvtColor(color_roi, cv2.COLOR_BGR2HSV)
        
        # ê°ˆìƒ‰ ê³„ì—´ (ë‚˜ë¬´ ë¬¸)
        brown_mask = cv2.inRange(hsv, np.array([5, 50, 20]), np.array([25, 255, 200]))
        
        # íšŒìƒ‰/í°ìƒ‰ ê³„ì—´ (ë„ì¥ ë¬¸)  
        gray_mask = cv2.inRange(hsv, np.array([0, 0, 100]), np.array([180, 30, 255]))
        
        door_color_ratio = (cv2.countNonZero(brown_mask) + cv2.countNonZero(gray_mask)) / color_roi.size
        confidence += door_color_ratio * 0.4
        
        # 2. ì—£ì§€ íŒ¨í„´ ë¶„ì„ (ë¬¸ì€ ì§ì„  ì—£ì§€ê°€ ë§ìŒ)
        edges = cv2.Canny(gray_roi, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        
        if 0.05 < edge_density < 0.3:  # ì ë‹¹í•œ ì—£ì§€ ë°€ë„
            confidence += 0.3
        
        # 3. ìˆ˜ì§ì„± ê²€ì¦ (ë¬¸ì€ ì„¸ë¡œ êµ¬ì¡°ë¬¼)
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=20, minLineLength=30, maxLineGap=10)
        if lines is not None:
            vertical_lines = 0
            for line in lines:
                x1, y1, x2, y2 = line[0]
                angle = abs(math.degrees(math.atan2(y2-y1, x2-x1)))
                if 80 < angle < 100:  # ìˆ˜ì§ì„ 
                    vertical_lines += 1
            
            if vertical_lines >= 2:
                confidence += 0.3
        
        return min(1.0, confidence)
    
    def match_door_standards(self, pixel_width, pixel_height):
        """ë¬¸ í‘œì¤€ ì¹˜ìˆ˜ ë§¤ì¹­"""
        # í•œêµ­ í‘œì¤€ ë¬¸ ì¹˜ìˆ˜ì™€ ë¹„êµ
        door_standards = self.standard_dimensions['door']
        
        # ì¢…íš¡ë¹„ ê¸°ë°˜ ë§¤ì¹­
        pixel_aspect = pixel_height / pixel_width
        
        best_match = None
        min_diff = float('inf')
        
        for real_width in door_standards['width']:
            for real_height in door_standards['height']:
                real_aspect = real_height / real_width
                diff = abs(pixel_aspect - real_aspect)
                
                if diff < min_diff:
                    min_diff = diff
                    best_match = {'width': real_width, 'height': real_height}
        
        return best_match or door_standards['typical']
    
    def detect_windows_with_standards(self, gray, color_image):
        """í‘œì¤€ ì¹˜ìˆ˜ ê¸°ë°˜ ì°½ë¬¸ ê°ì§€"""
        windows = []
        
        # ë°ì€ ì˜ì—­ ê°ì§€ (ì°½ë¬¸ = ìì—°ê´‘)
        _, bright_mask = cv2.threshold(gray, 140, 255, cv2.THRESH_BINARY)
        
        # ë…¸ì´ì¦ˆ ì œê±°
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
        bright_mask = cv2.morphologyEx(bright_mask, cv2.MORPH_CLOSE, kernel)
        
        contours, _ = cv2.findContours(bright_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for contour in contours:
            area = cv2.contourArea(contour)
            if 5000 < area < 200000:  # ì°½ë¬¸ í¬ê¸° ë²”ìœ„
                x, y, w, h = cv2.boundingRect(contour)
                aspect_ratio = w / h
                
                # ì°½ë¬¸ ì¢…íš¡ë¹„ (0.8~3.0)
                if 0.8 < aspect_ratio < 3.0:
                    confidence = self.verify_window_features(color_image[y:y+h, x:x+w], gray[y:y+h, x:x+w])
                    
                    if confidence > 0.4:
                        estimated_size = self.match_window_standards(w, h)
                        
                        windows.append({
                            'type': 'window',
                            'bbox': (x, y, w, h),
                            'confidence': confidence,
                            'aspect_ratio': aspect_ratio,
                            'estimated_real_size': estimated_size,
                            'pixel_size': {'width': w, 'height': h}
                        })
        
        return windows
    
    def verify_window_features(self, color_roi, gray_roi):
        """ì°½ë¬¸ íŠ¹ì§• ê²€ì¦"""
        if color_roi.size == 0:
            return 0.0
        
        confidence = 0.0
        
        # 1. ë°ê¸° ë¶„ì„
        mean_brightness = np.mean(gray_roi)
        if mean_brightness > 120:
            confidence += 0.4
        
        # 2. í”„ë ˆì„ ê²€ì¶œ (ì°½ë¬¸ í…Œë‘ë¦¬)
        edges = cv2.Canny(gray_roi, 30, 100)
        
        # ì§ì‚¬ê°í˜• í”„ë ˆì„ ì°¾ê¸°
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=15, minLineLength=20, maxLineGap=5)
        if lines is not None:
            horizontal_lines = 0
            vertical_lines = 0
            
            for line in lines:
                x1, y1, x2, y2 = line[0]
                angle = abs(math.degrees(math.atan2(y2-y1, x2-x1)))
                
                if angle < 20 or angle > 160:  # ìˆ˜í‰ì„ 
                    horizontal_lines += 1
                elif 70 < angle < 110:  # ìˆ˜ì§ì„ 
                    vertical_lines += 1
            
            if horizontal_lines >= 2 and vertical_lines >= 2:
                confidence += 0.4
        
        # 3. ìœ ë¦¬ì°½ ë°˜ì‚¬/íˆ¬ëª…ë„ (ë°ê¸° í¸ì°¨)
        brightness_std = np.std(gray_roi)
        if 20 < brightness_std < 60:  # ì ë‹¹í•œ ë°ê¸° í¸ì°¨
            confidence += 0.2
        
        return min(1.0, confidence)
    
    def match_window_standards(self, pixel_width, pixel_height):
        """ì°½ë¬¸ í‘œì¤€ ì¹˜ìˆ˜ ë§¤ì¹­"""
        window_standards = self.standard_dimensions['window']
        
        pixel_aspect = pixel_width / pixel_height
        
        best_match = None
        min_diff = float('inf')
        
        for real_width in window_standards['width']:
            for real_height in window_standards['height']:
                real_aspect = real_width / real_height
                diff = abs(pixel_aspect - real_aspect)
                
                if diff < min_diff:
                    min_diff = diff
                    best_match = {'width': real_width, 'height': real_height}
        
        return best_match or window_standards['typical']
    
    def detect_outlets_with_standards(self, gray):
        """ì½˜ì„¼íŠ¸ í‘œì¤€ ì¹˜ìˆ˜ ê°ì§€"""
        outlets = []
        
        edges = cv2.Canny(gray, 80, 200)
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for contour in contours:
            area = cv2.contourArea(contour)
            if 50 < area < 2000:  # ì½˜ì„¼íŠ¸ í¬ê¸°
                x, y, w, h = cv2.boundingRect(contour)
                aspect_ratio = w / h
                
                if 0.6 < aspect_ratio < 1.7:  # ì •ì‚¬ê°í˜•ì— ê°€ê¹Œìš´ í˜•íƒœ
                    outlets.append({
                        'type': 'outlet',
                        'bbox': (x, y, w, h),
                        'confidence': 0.5,
                        'estimated_real_size': self.standard_dimensions['outlet']['typical'],
                        'pixel_size': {'width': w, 'height': h}
                    })
        
        return outlets
    
    def detect_floor_patterns(self, gray):
        """ë°”ë‹¥ íŒ¨í„´ ê°ì§€ (íƒ€ì¼, ë§ˆë£¨ ë“±)"""
        patterns = []
        
        # ë°˜ë³µ íŒ¨í„´ ê²€ì¶œ (íƒ€ì¼ ë“±)
        # í…œí”Œë¦¿ ë§¤ì¹­ì´ë‚˜ FFT ê¸°ë°˜ íŒ¨í„´ ë¶„ì„ ê°€ëŠ¥
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ê·¸ë¦¬ë“œ íŒ¨í„´ ê²€ì¶œ
        
        return patterns  # í˜„ì¬ëŠ” ë¹ˆ ë°°ì—´ ë°˜í™˜
    
    def estimate_multiple_scales(self, detected_objects, image_shape):
        """ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì¶”ì •"""
        scale_candidates = []
        
        for obj in detected_objects:
            obj_type = obj['type']
            pixel_size = obj['pixel_size']
            estimated_real = obj['estimated_real_size']
            confidence = obj['confidence']
            
            if obj_type == 'door':
                # ë¬¸ ë†’ì´ ê¸°ì¤€ ìŠ¤ì¼€ì¼
                scale_height = estimated_real['height'] / pixel_size['height']
                scale_candidates.append({
                    'scale': scale_height,
                    'confidence': confidence,
                    'source': f'door_height_{estimated_real["height"]}cm',
                    'object': obj
                })
                
                # ë¬¸ ë„ˆë¹„ ê¸°ì¤€ ìŠ¤ì¼€ì¼
                scale_width = estimated_real['width'] / pixel_size['width']
                scale_candidates.append({
                    'scale': scale_width,
                    'confidence': confidence * 0.8,  # ë†’ì´ë³´ë‹¤ ì‹ ë¢°ë„ ë‚®ìŒ
                    'source': f'door_width_{estimated_real["width"]}cm',
                    'object': obj
                })
                
            elif obj_type == 'window':
                # ì°½ë¬¸ ë„ˆë¹„ ê¸°ì¤€
                scale_width = estimated_real['width'] / pixel_size['width']
                scale_candidates.append({
                    'scale': scale_width,
                    'confidence': confidence,
                    'source': f'window_width_{estimated_real["width"]}cm',
                    'object': obj
                })
                
                # ì°½ë¬¸ ë†’ì´ ê¸°ì¤€
                scale_height = estimated_real['height'] / pixel_size['height']
                scale_candidates.append({
                    'scale': scale_height,
                    'confidence': confidence * 0.9,
                    'source': f'window_height_{estimated_real["height"]}cm',
                    'object': obj
                })
                
            elif obj_type == 'outlet':
                # ì½˜ì„¼íŠ¸ í¬ê¸° ê¸°ì¤€
                scale_avg = (estimated_real['width'] + estimated_real['height']) / (pixel_size['width'] + pixel_size['height']) * 2
                scale_candidates.append({
                    'scale': scale_avg,
                    'confidence': confidence * 0.6,  # ì‘ì€ ê°ì²´ë¼ ì‹ ë¢°ë„ ë‚®ìŒ
                    'source': f'outlet_{estimated_real["width"]}cm',
                    'object': obj
                })
        
        # ìŠ¤ì¼€ì¼ì´ ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ ë°© í¬ê¸° ì¶”ì •
        if not scale_candidates:
            h, w = image_shape[:2]
            # ì¼ë°˜ì ì¸ ë°©: 3.5m x 4.0m ê°€ì •
            estimated_scale = 350 / min(w, h)  # ë” ì‘ì€ ìª½ì„ 3.5më¡œ ê°€ì •
            scale_candidates.append({
                'scale': estimated_scale,
                'confidence': 0.3,
                'source': 'default_room_estimation',
                'object': None
            })
        
        return scale_candidates
    
    def select_best_scale(self, scale_candidates):
        """ìµœì  ìŠ¤ì¼€ì¼ ì„ íƒ"""
        if not scale_candidates:
            return 0.5  # ê¸°ë³¸ê°’
        
        # ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê· 
        total_weight = sum(candidate['confidence'] for candidate in scale_candidates)
        
        if total_weight == 0:
            return scale_candidates[0]['scale']
        
        weighted_scale = sum(
            candidate['scale'] * candidate['confidence'] 
            for candidate in scale_candidates
        ) / total_weight
        
        return weighted_scale
    
    def detect_room_boundaries_advanced(self, processed_image, detected_objects):
        """ê³ ê¸‰ ë°© ê²½ê³„ì„  ê°ì§€"""
        # ê°ì²´ ì˜ì—­ ë§ˆìŠ¤í‚¹
        mask = self.create_advanced_mask(processed_image.shape, detected_objects)
        
        # ë§ˆìŠ¤í¬ ì ìš©ëœ ì—£ì§€
        edges = cv2.Canny(processed_image, 50, 150)
        masked_edges = cv2.bitwise_and(edges, mask)
        
        # ì§ì„  ê²€ì¶œ
        lines = cv2.HoughLinesP(
            masked_edges, 1, np.pi/180, threshold=50, 
            minLineLength=80, maxLineGap=30
        )
        
        if lines is None:
            return self.generate_default_corners(processed_image.shape)
        
        # ë°© ëª¨ì„œë¦¬ ì¶”ì¶œ
        corners = self.extract_room_corners_v2(lines, processed_image.shape)
        
        return corners
    
    def create_advanced_mask(self, image_shape, detected_objects):
        """ê³ ê¸‰ ë§ˆìŠ¤í¬ ìƒì„±"""
        h, w = image_shape[:2]
        mask = np.ones((h, w), dtype=np.uint8) * 255
        
        for obj in detected_objects:
            x, y, width, height = obj['bbox']
            # ê°ì²´ ì£¼ë³€ ì—¬ë°± ì„¤ì • (ê°ì²´ íƒ€ì…ë³„ ë‹¤ë¦„)
            if obj['type'] == 'door':
                margin = 15
            elif obj['type'] == 'window':
                margin = 10
            else:
                margin = 5
            
            x1 = max(0, x - margin)
            y1 = max(0, y - margin)
            x2 = min(w, x + width + margin)
            y2 = min(h, y + height + margin)
            
            mask[y1:y2, x1:x2] = 0
        
        return mask
    
    def extract_room_corners_v2(self, lines, image_shape):
        """ë°© ëª¨ì„œë¦¬ ì¶”ì¶œ v2"""
        h, w = image_shape[:2]
        
        # ìˆ˜í‰ì„ /ìˆ˜ì§ì„  ë¶„ë¥˜
        h_lines, v_lines = [], []
        
        for line in lines:
            x1, y1, x2, y2 = line[0]
            angle = math.degrees(math.atan2(y2 - y1, x2 - x1))
            length = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)
            
            if length > 50:
                if abs(angle) < 20 or abs(angle) > 160:
                    h_lines.append(line[0])
                elif 70 < abs(angle) < 110:
                    v_lines.append(line[0])
        
        # ê²½ê³„ì„  ì„ íƒ ë° êµì  ê³„ì‚°
        corners = []
        if len(h_lines) >= 2 and len(v_lines) >= 2:
            # ê²½ê³„ì„ ë“¤ ì„ íƒ
            boundaries = self.select_room_boundaries(h_lines, v_lines, w, h)
            
            # êµì  ê³„ì‚°
            if all(b is not None for b in boundaries.values()):
                corners = self.calculate_boundary_intersections(boundaries)
        
        # ë°±ì—… ë°©ë²•
        if len(corners) < 4:
            corners = self.generate_default_corners(image_shape)
        
        return corners[:4]
    
    def select_room_boundaries(self, h_lines, v_lines, width, height):
        """ë°© ê²½ê³„ì„  ì„ íƒ"""
        boundaries = {}
        
        if h_lines:
            boundaries['top'] = min(h_lines, key=lambda l: (l[1] + l[3]) / 2)
            boundaries['bottom'] = max(h_lines, key=lambda l: (l[1] + l[3]) / 2)
        
        if v_lines:
            boundaries['left'] = min(v_lines, key=lambda l: (l[0] + l[2]) / 2)
            boundaries['right'] = max(v_lines, key=lambda l: (l[0] + l[2]) / 2)
        
        return boundaries
    
    def calculate_boundary_intersections(self, boundaries):
        """ê²½ê³„ì„  êµì  ê³„ì‚°"""
        corners = []
        
        intersections = [
            ('top', 'left'),
            ('top', 'right'), 
            ('bottom', 'right'),
            ('bottom', 'left')
        ]
        
        for h_key, v_key in intersections:
            if h_key in boundaries and v_key in boundaries:
                intersection = self.line_intersection(boundaries[h_key], boundaries[v_key])
                if intersection:
                    corners.append(intersection)
        
        return corners
    
    def line_intersection(self, line1, line2):
        """ë‘ ì§ì„  êµì """
        x1, y1, x2, y2 = line1
        x3, y3, x4, y4 = line2
        
        denom = (x1 - x2) * (y3 - y4) - (y1 - y2) * (x3 - x4)
        if abs(denom) < 1e-10:
            return None
        
        t = ((x1 - x3) * (y3 - y4) - (y1 - y3) * (x3 - x4)) / denom
        
        x = x1 + t * (x2 - x1)
        y = y1 + t * (y2 - y1)
        
        return (int(x), int(y))
    
    def generate_default_corners(self, image_shape):
        """ê¸°ë³¸ ëª¨ì„œë¦¬ì  ìƒì„±"""
        h, w = image_shape[:2]
        margin = min(w, h) * 0.1
        
        return [
            (int(margin), int(margin)),
            (int(w - margin), int(margin)),
            (int(w - margin), int(h - margin)),
            (int(margin), int(h - margin))
        ]
    
    def calculate_verified_dimensions(self, corners, best_scale, scale_candidates):
        """ê²€ì¦ëœ ì¹˜ìˆ˜ ê³„ì‚°"""
        if len(corners) < 4:
            return {'width': 0, 'height': 0, 'area': 0, 'perimeter': 0, 'confidence': 0.0}
        
        # í”½ì…€ ê±°ë¦¬
        tl, tr, br, bl = corners
        width_pixels = math.sqrt((tr[0] - tl[0])**2 + (tr[1] - tl[1])**2)
        height_pixels = math.sqrt((bl[0] - tl[0])**2 + (bl[1] - tl[1])**2)
        
        # ì‹¤ì œ í¬ê¸°
        width_cm = width_pixels * best_scale
        height_cm = height_pixels * best_scale
        area_m2 = (width_cm * height_cm) / 10000
        perimeter_m = (width_cm + height_cm) * 2 / 100
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self.calculate_comprehensive_confidence(
            corners, width_cm, height_cm, scale_candidates
        )
        
        return {
            'width': round(width_cm, 1),
            'height': round(height_cm, 1), 
            'area': round(area_m2, 2),
            'perimeter': round(perimeter_m, 2),
            'confidence': confidence
        }
    
    def calculate_comprehensive_confidence(self, corners, width_cm, height_cm, scale_candidates):
        """ì¢…í•© ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 1.0
        
        # 1. ìŠ¤ì¼€ì¼ ì‹ ë¢°ë„
        if scale_candidates:
            avg_scale_confidence = sum(sc['confidence'] for sc in scale_candidates) / len(scale_candidates)
            confidence *= avg_scale_confidence
        
        # 2. í¬ê¸° í•©ë¦¬ì„± (í•œêµ­ ì£¼ê±° ê¸°ì¤€)
        if 200 <= width_cm <= 600 and 200 <= height_cm <= 600:
            confidence *= 1.0
        elif 150 <= width_cm <= 800 and 150 <= height_cm <= 800:
            confidence *= 0.8
        else:
            confidence *= 0.4
        
        # 3. ì¢…íš¡ë¹„ í•©ë¦¬ì„±
        aspect_ratio = max(width_cm, height_cm) / min(width_cm, height_cm)
        if aspect_ratio <= 2.0:
            confidence *= 1.0
        elif aspect_ratio <= 3.0:
            confidence *= 0.7
        else:
            confidence *= 0.4
        
        # 4. ì§ì‚¬ê°í˜• í˜•íƒœ
        rectangularity = self.check_rectangularity(corners)
        confidence *= rectangularity
        
        return max(0.1, min(1.0, confidence))
    
    def check_rectangularity(self, corners):
        """ì§ì‚¬ê°í˜• í˜•íƒœ í™•ì¸"""
        if len(corners) < 4:
            return 0.0
        
        angles = []
        for i in range(4):
            p1 = corners[i]
            p2 = corners[(i + 1) % 4]
            p3 = corners[(i + 2) % 4]
            
            v1 = (p1[0] - p2[0], p1[1] - p2[1])
            v2 = (p3[0] - p2[0], p3[1] - p2[1])
            
            dot_product = v1[0] * v2[0] + v1[1] * v2[1]
            norm1 = math.sqrt(v1[0]**2 + v1[1]**2)
            norm2 = math.sqrt(v2[0]**2 + v2[1]**2)
            
            if norm1 > 0 and norm2 > 0:
                cos_angle = max(-1, min(1, dot_product / (norm1 * norm2)))
                angle = math.degrees(math.acos(cos_angle))
                angles.append(angle)
        
        rectangularity = 1.0
        for angle in angles:
            diff = abs(angle - 90)
            rectangularity *= max(0.2, 1.0 - diff / 45)
        
        return rectangularity
    
    def comprehensive_analysis(self, dimensions, detected_objects, scale_candidates):
        """ì¢…í•© ë¶„ì„ ë° ëŒ€ì•ˆ ì œì‹œ"""
        # ì£¼ ê²°ê³¼
        primary = dimensions
        
        # ëŒ€ì•ˆ ì‹œë‚˜ë¦¬ì˜¤ë“¤
        alternatives = []
        
        # ê° ìŠ¤ì¼€ì¼ í›„ë³´ë³„ë¡œ ëŒ€ì•ˆ ê³„ì‚°
        for i, scale_candidate in enumerate(scale_candidates[:3]):  # ìƒìœ„ 3ê°œë§Œ
            alt_scale = scale_candidate['scale']
            alt_width = primary['width'] * (alt_scale / (primary['width'] / 100))  # ê°„ë‹¨ ë¹„ë¡€ ê³„ì‚°
            alt_height = primary['height'] * (alt_scale / (primary['height'] / 100))
            
            alternatives.append({
                'scenario': f"ì‹œë‚˜ë¦¬ì˜¤ {i+1}",
                'source': scale_candidate['source'],
                'width': round(alt_width, 1),
                'height': round(alt_height, 1),
                'area': round(alt_width * alt_height / 10000, 2),
                'confidence': scale_candidate['confidence']
            })
        
        # ì¼ë°˜ì ì¸ ë°© í¬ê¸°ì™€ ë¹„êµ
        room_category = self.categorize_room_size(primary['width'], primary['height'])
        
        return {
            'primary': primary,
            'alternatives': alternatives,
            'room_category': room_category,
            'confidence': primary['confidence']
        }
    
    def categorize_room_size(self, width_cm, height_cm):
        """ë°© í¬ê¸° ë¶„ë¥˜"""
        area_m2 = width_cm * height_cm / 10000
        
        if area_m2 < 10:
            return "ì†Œí˜• ë°© (10mÂ² ë¯¸ë§Œ)"
        elif area_m2 < 20:
            return "ì¤‘í˜• ë°© (10-20mÂ²)"
        elif area_m2 < 30:
            return "ëŒ€í˜• ë°© (20-30mÂ²)"
        else:
            return "íŠ¹ëŒ€í˜• ë°© (30mÂ² ì´ìƒ)"
    
    def absolute_visualization(self, image, corners, detected_objects, analysis_result):
        """ì ˆëŒ€ í¬ê¸° ì‹œê°í™”"""
        result = image.copy()
        
        # 1. ê°ì§€ëœ ê°ì²´ë“¤ í‘œì‹œ (ìŠ¤ì¼€ì¼ ê¸°ì¤€ ê°ì²´ ê°•ì¡°)
        for obj in detected_objects:
            x, y, w, h = obj['bbox']
            obj_type = obj['type']
            confidence = obj['confidence']
            
            # ê°ì²´ íƒ€ì…ë³„ ìƒ‰ìƒ
            colors = {
                'door': (255, 0, 0),      # ë¹¨ê°•
                'window': (0, 255, 255),  # ë…¸ë‘  
                'outlet': (255, 0, 255)   # ë§ˆì  íƒ€
            }
            
            color = colors.get(obj_type, (128, 128, 128))
            thickness = 4 if obj.get('used_for_scale') else 2
            
            # ê°ì²´ ë°•ìŠ¤
            cv2.rectangle(result, (x, y), (x + w, y + h), color, thickness)
            
            # ë¼ë²¨ (ì‹¤ì œ ì¶”ì • í¬ê¸° í¬í•¨)
            real_size = obj['estimated_real_size']
            if obj_type == 'door':
                label = f"ë¬¸ {real_size['width']}x{real_size['height']}cm"
            elif obj_type == 'window':
                label = f"ì°½ë¬¸ {real_size['width']}x{real_size['height']}cm"
            else:
                label = f"{obj_type} {confidence:.2f}"
            
            # ë¼ë²¨ ë°°ê²½
            text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            cv2.rectangle(result, (x, y - 25), (x + text_size[0] + 10, y), color, -1)
            cv2.putText(result, label, (x + 5, y - 8),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # 2. ë°© ê²½ê³„ì„  ë° ëª¨ì„œë¦¬ì 
        if len(corners) >= 4:
            pts = np.array(corners, dtype=np.int32)
            
            # ë°˜íˆ¬ëª… ë°© ì˜ì—­
            overlay = result.copy()
            cv2.fillPoly(overlay, [pts], (0, 255, 0))
            result = cv2.addWeighted(result, 0.75, overlay, 0.25, 0)
            
            # ë°© ê²½ê³„ì„ 
            cv2.polylines(result, [pts], True, (0, 255, 0), 4)
            
            # ëª¨ì„œë¦¬ì 
            for i, corner in enumerate(corners):
                cv2.circle(result, corner, 12, (255, 0, 0), -1)
                cv2.circle(result, corner, 16, (255, 255, 255), 3)
                cv2.putText(result, str(i+1), 
                           (corner[0] + 20, corner[1] + 20),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        # 3. ìƒì„¸ ì •ë³´ íŒ¨ë„
        self.draw_comprehensive_info_panel(result, analysis_result)
        
        # 4. ì¹˜ìˆ˜ ë¼ë²¨
        if len(corners) >= 4:
            self.draw_absolute_dimension_labels(result, corners, analysis_result['primary'])
        
        # base64 ì¸ì½”ë”©
        _, buffer = cv2.imencode('.png', result)
        result_base64 = base64.b64encode(buffer).decode('utf-8')
        
        return f"data:image/png;base64,{result_base64}"
    
    def draw_comprehensive_info_panel(self, image, analysis_result):
        """ì¢…í•© ì •ë³´ íŒ¨ë„"""
        panel_height = 200
        panel_width = image.shape[1]
        
        panel = np.zeros((panel_height, panel_width, 3), dtype=np.uint8)
        panel.fill(20)
        
        # ì œëª©
        cv2.putText(panel, "Absolute Room Size Analysis", (20, 25),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        
        # ì£¼ ê²°ê³¼
        primary = analysis_result['primary']
        main_info = [
            f"Primary: {primary['width']}cm x {primary['height']}cm",
            f"Area: {primary['area']}mÂ² | Confidence: {primary['confidence']:.1%}",
            f"Category: {analysis_result['room_category']}"
        ]
        
        for i, line in enumerate(main_info):
            cv2.putText(panel, line, (20, 55 + i * 20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        # ëŒ€ì•ˆ ì‹œë‚˜ë¦¬ì˜¤
        if analysis_result['alternatives']:
            cv2.putText(panel, "Alternative Scenarios:", (20, 125),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)
            
            for i, alt in enumerate(analysis_result['alternatives'][:2]):  # ìƒìœ„ 2ê°œë§Œ
                alt_text = f"{alt['scenario']}: {alt['width']}x{alt['height']}cm ({alt['confidence']:.1%})"
                cv2.putText(panel, alt_text, (20, 145 + i * 18),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
        
        # íŒ¨ë„ì„ ì´ë¯¸ì§€ì— ì¶”ê°€
        result = np.vstack([image, panel])
        image[:] = result[:image.shape[0]]
    
    def draw_absolute_dimension_labels(self, image, corners, dimensions):
        """ì ˆëŒ€ ì¹˜ìˆ˜ ë¼ë²¨"""
        # ê°€ë¡œ ì¹˜ìˆ˜ (ìƒë‹¨)
        top_center = (
            (corners[0][0] + corners[1][0]) // 2,
            max(40, corners[0][1] - 50)
        )
        
        width_text = f"{dimensions['width']}cm"
        text_size = cv2.getTextSize(width_text, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)[0]
        
        # ë°°ê²½ ë°•ìŠ¤
        cv2.rectangle(image, 
                     (top_center[0] - text_size[0]//2 - 10, top_center[1] - text_size[1] - 10),
                     (top_center[0] + text_size[0]//2 + 10, top_center[1] + 10),
                     (0, 0, 0), -1)
        cv2.rectangle(image, 
                     (top_center[0] - text_size[0]//2 - 10, top_center[1] - text_size[1] - 10),
                     (top_center[0] + text_size[0]//2 + 10, top_center[1] + 10),
                     (0, 255, 255), 2)
        
        cv2.putText(image, width_text, 
                   (top_center[0] - text_size[0]//2, top_center[1] - 5),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 255), 3)
        
        # ì„¸ë¡œ ì¹˜ìˆ˜ (ì¢Œì¸¡)
        left_center = (
            max(100, corners[0][0] - 120),
            (corners[0][1] + corners[3][1]) // 2
        )
        
        height_text = f"{dimensions['height']}cm"
        text_size = cv2.getTextSize(height_text, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)[0]
        
        # ë°°ê²½ ë°•ìŠ¤
        cv2.rectangle(image, 
                     (left_center[0] - text_size[0]//2 - 10, left_center[1] - text_size[1]//2 - 10),
                     (left_center[0] + text_size[0]//2 + 10, left_center[1] + text_size[1]//2 + 10),
                     (0, 0, 0), -1)
        cv2.rectangle(image, 
                     (left_center[0] - text_size[0]//2 - 10, left_center[1] - text_size[1]//2 - 10),
                     (left_center[0] + text_size[0]//2 + 10, left_center[1] + text_size[1]//2 + 10),
                     (0, 255, 255), 2)
        
        cv2.putText(image, height_text, 
                   (left_center[0] - text_size[0]//2, left_center[1] + text_size[1]//2 - 5),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 255), 3)

# Flask ë¼ìš°íŠ¸
analyzer = AbsoluteRoomAnalyzer()

@app.route('/')
def index():
    return render_template('room_analyzer.html')

@app.route('/api/analyze', methods=['POST'])
def analyze_room():
    try:
        data = request.get_json()
        
        image_data = data.get('image')
        reference_size = data.get('reference_size')  # 3ë‹¨ê³„ì—ì„œëŠ” ë¬´ì‹œë¨
        options = data.get('options', {})
        
        if not image_data:
            return jsonify({'success': False, 'error': 'ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.'})
        
        logger.info("3ë‹¨ê³„ ì ˆëŒ€ í¬ê¸° ì¶”ì • ë¶„ì„ ì‹œì‘")
        result = analyzer.analyze_image(image_data, reference_size, options)
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"API ì˜¤ë¥˜: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/health')
def health_check():
    return jsonify({
        'status': 'healthy',
        'version': '3.0.0',
        'features': [
            'absolute_size_estimation', 
            'standard_object_detection', 
            'multi_scale_analysis',
            'confidence_scoring',
            'alternative_scenarios'
        ],
        'timestamp': datetime.now().isoformat()
    })

if __name__ == '__main__':
    print("ğŸš€ 3ë‹¨ê³„ ì ˆëŒ€ í¬ê¸° ì¶”ì • ì‹œìŠ¤í…œì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ğŸ“ http://localhost:5000 ì—ì„œ ì ‘ì†í•˜ì„¸ìš”")
    print("ğŸ¯ 3ë‹¨ê³„ í˜ì‹  ê¸°ëŠ¥:")
    print("  ğŸ  í•œêµ­ ê±´ì¶• í‘œì¤€ ê¸°ë°˜ ë¶„ì„")
    print("  ğŸ“ ë¬¸/ì°½ë¬¸ í‘œì¤€ ì¹˜ìˆ˜ ìë™ ë§¤ì¹­")
    print("  ğŸ¯ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ í›„ë³´ ìƒì„± ë° ê²€ì¦")
    print("  ğŸ“Š ì‹ ë¢°ë„ ê¸°ë°˜ ìµœì  ìŠ¤ì¼€ì¼ ì„ íƒ")
    print("  ğŸ“‹ ëŒ€ì•ˆ ì‹œë‚˜ë¦¬ì˜¤ ì œì‹œ")
    print("  ğŸ† ë°© í¬ê¸° ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜")
    print("  âœ¨ ê¸°ì¤€ í¬ê¸° ì…ë ¥ ë¶ˆí•„ìš”!")
    app.run(debug=True, host='0.0.0.0', port=5000)